{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62744b32-d238-449a-9faf-9bf0cb775ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1bfdde-0504-443d-a630-13a023a47595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаемся к локальному Qdrant\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "\n",
    "# КОНФИГ\n",
    "COLLECTION_NAME = \"nlp2025_chunks\"\n",
    "VECTOR_SIZE = 1024\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc14ef-a657-446b-991c-d151ccda951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Проверяем и удаляем, если уже есть (чтобы начать с чистого листа)\n",
    "if client.collection_exists(collection_name=COLLECTION_NAME):\n",
    "    client.delete_collection(collection_name=COLLECTION_NAME)\n",
    "    print(f\"Коллекция '{COLLECTION_NAME}' удалена.\")\n",
    "\n",
    "# 2. Создаем заново\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(\n",
    "        size=VECTOR_SIZE, \n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "print(f\"Коллекция '{COLLECTION_NAME}' успешно создана! Готовы к заливке.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2c7eb-edf5-4fa8-8b11-e5e4e793ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к файлу\n",
    "parquet_file = \"../data/processed/all_chunks_with_embeddings.parquet\"\n",
    "\n",
    "print(\"Читаем Parquet файл...\")\n",
    "df = pd.read_parquet(parquet_file)\n",
    "print(f\"Загружено строк: {len(df)}\")\n",
    "\n",
    "points_batch = []\n",
    "total_records = len(df)\n",
    "\n",
    "# Итерируемся по датафрейму\n",
    "print(\"Начинаем заливку в Qdrant...\")\n",
    "for i, row in tqdm(df.iterrows(), total=total_records, desc=\"Uploading\"):\n",
    "    \n",
    "    # Конвертация numpy array -> list float32\n",
    "    # Это критично, чтобы не словить ошибку сериализации JSON\n",
    "    vector = row[\"embedding\"].astype(np.float32).tolist()\n",
    "    \n",
    "    # Сборка метаданных\n",
    "    payload = {\n",
    "        \"text\": row[\"text\"],\n",
    "        \"source\": row[\"source_path\"],\n",
    "        # Распаковка остальных метаданных, если есть\n",
    "        **(row[\"metadata\"] if row[\"metadata\"] else {}) \n",
    "    }\n",
    "\n",
    "    # Добавляем точку в буфер\n",
    "    points_batch.append(\n",
    "        PointStruct(\n",
    "            id=i,  # Используем индекс DataFrame как ID\n",
    "            vector=vector,\n",
    "            payload=payload\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Если буфер заполнился — отправляем\n",
    "    if len(points_batch) >= BATCH_SIZE:\n",
    "        client.upsert(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            points=points_batch,\n",
    "            wait=False # Не ждем подтверждения записи на диск (быстрее)\n",
    "        )\n",
    "        points_batch = [] # Очищаем буфер\n",
    "\n",
    "# Дозаливаем остатки, если буфер не пуст\n",
    "if points_batch:\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=points_batch,\n",
    "        wait=True # Тут ждем, чтобы убедиться, что всё закончилось\n",
    "    )\n",
    "\n",
    "print(\"Заливка завершена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076d401-5403-47cc-9884-a2f7b7762f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd2ebc-404b-47fc-b144-80303fbca85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовый поиск (берем вектор из датасета для примера)\n",
    "test_vector = df.iloc[0][\"embedding\"].astype(np.float32).tolist()\n",
    "\n",
    "hits = client.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=test_vector,\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "print(\"\\nТестовый поиск (Top-3):\")\n",
    "for hit in hits.points:\n",
    "    print(f\"ID: {hit.id}, Score: {hit.score}\")\n",
    "    if hit.payload:\n",
    "        print(f\"Payload: {hit.payload}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add44319-c1b0-4548-8e8d-a8578a937b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab3e30d-fc7d-4837-80e4-f0bdbce255bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_vector = np.random.uniform(low=-1.0, high=1.0, size=(VECTOR_SIZE,)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8bae1f-9a11-4fb2-9f58-6c6bc2ae9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = client.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=synthetic_vector,\n",
    "    limit=5,\n",
    "    with_payload=True,\n",
    "    with_vectors=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acec3b41-69a5-47e0-bdaa-76ec328dae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=311079, version=623, score=0.12865478, payload={'text': 'RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph: ###### Abstract  \\nIn knowledge graph embedding, leveraging relation specific entity transformation has markedly enhanced performance. However, the consistency of embedding differences before and after transformation remains unaddressed, risking the loss of valuable inductive bias inherent in the embeddings.\\nThis inconsistency stems from two problems. First, transformation representations are specified for relations in a disconnected manner, allowing dissimilar transformations and corresponding entity embeddings for similar relations.\\nSecond, a generalized plug-in approach as a SFBR (Semantic Filter Based on Relations) disrupts this consistency through excessive concentration of entity embeddings under entity-based regularization, generating indistinguishable score distributions among relations.\\nIn this paper,\\nwe introduce a plug-in KGE method, Relation-Semantics Consistent Filter (RSCF).\\nIts entity transformation has three features for enhancing semantic consistency:\\n1) shared affine transformation of relation embeddings across all relations, 2) rooted entity transformation that adds an entity embedding to its change represented by the transformed vector, and 3) normalization of the change to prevent scale reduction.\\nTo amplify the advantages of consistency that preserve semantics on embeddings, RSCF adds relation transformation and prediction modules for enhancing the semantics.\\nIn knowledge graph completion tasks with distance-based and tensor decomposition models,\\nRSCF significantly outperforms state-of-the-art KGE methods, showing robustness across all relations and their frequencies.  \\nRSCF: Relation-Semantics Consistent Filter for Entity Embedding\\nof Knowledge Graph  \\nJunsik Kim, Jinwook Park,\\nKangil Kim††thanks:  Corresponding author.  \\nAI Graduate School  \\nGwangju Institute of Science and Technology  \\njunsikkim@gm.gist.ac.kr,\\njinwookpark@gm.gist.ac.kr,  \\nkangil.kim.01@gmail.com', 'source': 'D:\\\\GitHub\\\\ArXiv_Info_System\\\\data\\\\raw\\\\html\\\\2505.20813v3.html', 'Header_1': 'RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph', 'Header_2': None, 'Header_3': None}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=91427, version=183, score=0.12715116, payload={'text': 'Diversity-driven Data Selection for Language Model Tuning through Sparse Autoencoder > 4 Methods and Experiments > 4.2 Experimental Settings: Configurations. For all SFT experiments, we use 8 Nvidia A100 80G GPUs and the stanford alpaca code base. Following similar configurations in ([Zhao etal.,](https://arxiv.org/html/2502.14050v2#bib.bib85) ), we set the maximum length to be $1,024$ for data selected from Alpaca-52k and $2,048$ from WizardLM\\\\_evol\\\\_instruct\\\\_70k. We always set the batch size to 128, learning\\\\_rate to 1e-5, weight\\\\_decay to 0.1, and warmup\\\\_ratio to 0.03. We set epochs to 15 for $1$ k and $3$ k data, $5$ for $5$ k data, and $3$ for full data.  \\nEvaluation.\\nThe selection of SFT data aims to elicit superior instruction-following abilities, but the evaluation lacks standardization.\\nFor a comprehensive evaluation, we use IFEval (Zhou etal., [2023](https://arxiv.org/html/2502.14050v2#bib.bib87)) for strict evaluation since it can accurately measure the response that adheres to the complex instructions through verifiable instructions, such as \"mention the keyword of AI at least 3 times\".\\nWe also use LLM- and Human-as-a-Judge for head-to-head evaluation and report the results on the AlpacaEval 2.0 leadboard as additional metric.', 'source': 'D:\\\\GitHub\\\\ArXiv_Info_System\\\\data\\\\raw\\\\html\\\\2502.14050v2.html', 'Header_1': 'Diversity-driven Data Selection for Language Model Tuning through Sparse Autoencoder', 'Header_2': '4 Methods and Experiments', 'Header_3': '4.2 Experimental Settings'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=115796, version=232, score=0.12537695, payload={'text': 'Are All Spanish Doctors Male? Evaluating Gender Bias in German Machine Translation > Appendix A Appendix > A.1 Occupation Statistics: | 521Fa | Fahrzeugführung im Straßenverkehr | Fahrerin, Fahrer |\\n| 531OP | Obj.-, Pers.-, Brandschutz, Arbeitssicherh. | Aufseher, Aufseherin, Wachfrau, Wachmann, Feuerwehrfrau, Feuerwehrmann, Ermittlerin, Inspektorin, Inspektor, Ermittler |\\n| 532Po | Polizei, Kriminald., Gerichts, Justizvollz. | Polizistin, Polizist, Polizisten |\\n| 541Re | Reinigung | Reiniger, Reinigerin |\\n| 621Vo | Verkauf (ohne Produktspezialisierung) | Kassierer, Kassiererin, Verkäuferin, Verkäufer |\\n| 632Ho | Hotellerie | Rezeptionistin, Rezeptionisten |\\n| 633Ga | Gastronomie | Barkeeper, Barkeeperin |\\n| 711GV | Geschäftsführung und Vorstand | Geschäftsführer, Geschäftsführerin, Chef, Chefin, Manager, Managerin, Vorgesetzte, Vorgesetzten |\\n| 714BS | Büro und Sekretariat | Assistent, Assistentin, Sekretärin, Sekretär |\\n| 715PD | Personalwesen und -dienstleistung | Beraterin, Berater |\\n| 721VF | Versicherungs- u. Finanzdienstleistungen | Analystin, Analyst, Aktienmaklerin, Aktienmakler |\\n| 722Rw | Rechnungswesen, Controlling und Revision | Buchhalter, Buchhalterin, Wirtschaftsprüfer, Wirtschaftsprüferin |\\n| 731Rb | Rechtsberatung, -sprechung und -ordnung | Anwältin, Anwalt, Rechtsassistent, Rechtsassistentin |\\n| 732Ve | Verwaltung | Verwalter, Verwalterin |', 'source': 'D:\\\\GitHub\\\\ArXiv_Info_System\\\\data\\\\raw\\\\html\\\\2502.19104v2.html', 'Header_1': 'Are All Spanish Doctors Male? Evaluating Gender Bias in German Machine Translation', 'Header_2': 'Appendix A Appendix', 'Header_3': 'A.1 Occupation Statistics'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=217505, version=436, score=0.12368301, payload={'text': 'Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models > 3 Method > 3.2 Information Gain-guided Data Debiasing Goal: | --- | --- | --- | --- |\\n|  | $\\\\displaystyle N(y_{i},b_{k})=N(y_{j},b_{k}).$ |  | (6) |  \\nwhere $N(y_{i},b_{k})$ denotes the number of instances whose answer and biased feature are $y_{i}$ and $b_{k}$ , respectively. The Eq.[6](https://arxiv.org/html/2504.12898v3#S3.Ex6 \"In 3.2 Information Gain-guided Data Debiasing Goal ‣ 3 Method ‣ Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models\") formalizes the information gain-guided data debiasing goal. To the best of our knowledge, we are the first to establish strict criteria that an unbiased instruction-tuning dataset must satisfy. Note that even if the number $N$ exhibits slight disparities, LLMs are unlikely to learn these subtle correlations. Therefore, we relax the strict equality in Eq.[6](https://arxiv.org/html/2504.12898v3#S3.Ex6 \"In 3.2 Information Gain-guided Data Debiasing Goal ‣ 3 Method ‣ Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models\") to an approximate equality as shown in Figure[2](https://arxiv.org/html/2504.12898v3#S2.F2 \"Figure 2 ‣ 2 Biased Features within the Instruction-tuning Datasets ‣ Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models\")(b).  \\nFor scenarios where the value space of the biased feature $B$ and answer $Y$ can be easily enumerated, such as the negation bias in the sentiment analysis task111A negation word either exists in the sentence or not, and the value space of the answer for sentiment analysis task is positive and negative., this data debiasing goal can directly guide the subsequent causal intervention process.\\nHowever, for scenarios where the value space of the biased feature $B$ or the answer $Y$ is difficult to enumerate, we will utilize an automatic regularization method. The automatic regularization method can be divided into two aspects:', 'source': 'D:\\\\GitHub\\\\ArXiv_Info_System\\\\data\\\\raw\\\\html\\\\2504.12898v3.html', 'Header_1': 'Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models', 'Header_2': '3 Method', 'Header_3': '3.2 Information Gain-guided Data Debiasing Goal'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=727413, version=1455, score=0.12287286, payload={'text': 'Tree Matching Networks for Natural Language Inference: Parameter-Efficient Semantic Understanding via Dependency Parse Trees > Introduction > Contributions: We present an adaptation of Graph Matching Networks to linguistic dependency trees with rich features combining BERT embeddings, POS tags, and morphological annotations for natural language inference. Our evaluation compares tree-based GNN and BERT architectures at matched parameter counts ( $\\\\sim$ 36M) with identical training protocols, enabling controlled analysis of structural inductive bias. We identify a scaling plateau where 2 $\\\\times$ parameter increases yield minimal improvement, suggesting the aggregation mechanism as an architectural bottleneck. Through systematic comparison of matching versus embedding architectures, we isolate the contribution of cross-graph attention and observe compatibility differences between tree-based and transformer-based approaches.', 'source': 'D:\\\\GitHub\\\\ArXiv_Info_System\\\\data\\\\raw\\\\html\\\\2512.00204v2.html', 'Header_1': 'Tree Matching Networks for Natural Language Inference: Parameter-Efficient Semantic Understanding via Dependency Parse Trees', 'Header_2': 'Introduction', 'Header_3': 'Contributions'}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0da29-132b-4eed-92ae-26cb29600719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
