{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5c4131-1375-430f-9fbf-d0a09199c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d75a581-e495-4267-8f73-8772b1a322a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "COLLECTION_NAME = \"nlp2025_chunks\"\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e12a435-de60-4123-8e29-6161df498915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given 10 chunks\n",
      "\n",
      "Chunk ID: 515634\n",
      "Paper title: How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations\n",
      "Chunk text: How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations > 5 Results & Analysis > 5.1 Comparison Between LLMs and Humans: The results of the evaluation based on the objective metric are shown in Table[2](https://arxiv.org/html/2508.21137v2#S4.T2 \"Table 2 ‣ Susceptibility to the Anchoring Effect ‣ 4.3 Evaluation Metrics ‣ 4 Experimental Settings ‣ How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations\"), and those based on the subjective metric are shown in Table[3](https://arxiv.org/html/2508.21137v2#S4.T3 \"Table 3 ‣ Susceptibility to the Anchoring Effect ‣ 4.3 Evaluation Metrics ‣ 4 Experimental Settings ‣ How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations\"). Here, we compare conditions rather than models, in reference to studies on the anchoring effect in humans. It can be seen that the standard deviations in Table[2](https://arxiv.org/html/2508.21137v2#S4.T2 \"Table 2 ‣ Susceptibility to the Anchoring Effect ‣ 4.3 Evaluation Metrics ‣ 4 Experimental Settings ‣ How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations\") are relatively large, reflecting the diversity of products subject to negotiation. For example, in negotiations over a stool, the seller’s target price is $15 while the buyer’s target price is $13, and the agreed price can easily fall outside the range between $13 and $15, resulting in large fluctuations in utility.\n",
      "------------------------------\n",
      "Chunk ID: 184632\n",
      "Paper title: Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences\n",
      "Chunk text: Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences > 2 Related Work > 2.1 Chain-of-Thought Prompting: also uses few-shot prompting to query LLMs and gathers the interaction histories with user feedback to concatenate with the original prompt. Besides, there are many retrieval-based in-context learning methodsLuo etal. ([2024](https://arxiv.org/html/2504.00473v1#bib.bib14)) that leverage existing databases and retrieval systems. Unlike these methods, RoSE puts more emphasis on the self-improvement of LLMs without any external data or feedback.\n",
      "------------------------------\n",
      "Chunk ID: 185421\n",
      "Paper title: ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations\n",
      "Chunk text: ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations > 4 Experiments > 4.4 Ablation Studies: | w/o ref. content | 3.60 | 3.25 | 2.58 | 2.91 | 3.19 | 15.53 |\n",
      "| $\\Delta$ | +0.03 | +0.41 | +0.29 | -0.02 | -0.02 | +0.68 |  \n",
      "Table 2: Impact of reference content integration on generation quality.  \n",
      "As shown in Table[2](https://arxiv.org/html/2504.00824v2#S4.T2 \"Table 2 ‣ 4.4.2 Impact of Reference Content Integration ‣ 4.4 Ablation Studies ‣ 4 Experiments ‣ ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations\"), the two variants perform similarly on Relevance, Completeness, and Innovation. However, differences appear in Coherence (3.66 vs. 3.25) and Academic Rigor (2.87 vs. 2.58), leading to a higher total score for the standard ScholarCopilot (16.21 vs. 15.53). Analysis indicates two reasons. First, access to reference content reduces inaccuracies when describing cited works. Second, reference details provide contextual information that improves coherence, especially during comparisons or transitions between ideas.  \n",
      "Qualitative evaluation shows the variant without reference content tends to cite sources with general statements, whereas the standard approach integrates specific details for clearer connections. For example, when discussing neural networks, the standard model states: ”Transformer models leverage self-attention mechanisms to capture long-range dependencies cite(vaswani2017attention), specifically through a multi-headed approach that projects queries, keys, and values into separate subspaces.” In contrast, the variant without reference content produces simpler statements like ”Transformer models use self-attention for capturing dependencies cite(vaswani2017attention).”\n",
      "------------------------------\n",
      "Chunk ID: 289762\n",
      "Paper title: Systematic Evaluation of Machine-Generated Reasoning and PHQ-9 Labeling for Depression Detection Using Large Language Models\n",
      "Chunk text: Systematic Evaluation of Machine-Generated Reasoning and PHQ-9 Labeling for Depression Detection Using Large Language Models > 3 LLM Learning & Tuning Framework > 3.4 Quality Analysis of Generated Diagnoses: (b) the influence of explicit mention of depression-related keywords.\n",
      "3) Comparative Analysis: Compare different reasoning schemes w.r.t. the sequence of the key subtask “checkpoints”, which is based on human observations of the generated diagnoses.  \n",
      "To evaluate the performance of the overall joint decision-making for depression detection, we define the correct ratio $C$ as:  \n",
      "|  |  |  |  |\n",
      "| --- | --- | --- | --- |\n",
      "|  | $C=\\frac{N_{c}}{N}$ |  | (2) |  \n",
      "where $N_{c}$ represents the number of samples with fully correct responses, and $N$ is the total number of input samples.\n",
      "------------------------------\n",
      "Chunk ID: 409834\n",
      "Paper title: Trilemma of Truth in Large Language Models\n",
      "Chunk text: Trilemma of Truth in Large Language Models > 5 Results > 5.1 Veracity Directions: To show that the truthfulness and falsehood directions are not simple opposites, we examine the is-true and is-false directions identified by both the multiclass SVM probe and the sAwMIL probe.  \n",
      "![Refer to caption](x3.png)  \n",
      "Figure 3: Similarity between is-true and is-false directions across datasets and probes (values extracted from the best-performing layer and averaged across 16 LLMs).\n",
      "(A) Cosine similarity between the two directions.\n",
      "If the two directions were perfectly opposite, the cosine similarity would be closer to $-1$ , indicating a single bidirectional axis of truth and falsehood.\n",
      "Instead, all probes exhibit lesser opposition, with the better-performing and more generalizable probe (sAwMIL) showing a smaller angle between is-true and is-false.\n",
      "(B) Spearman correlation between scores predicted along the two directions (evaluated only on true and false statements).\n",
      "Perfectly bidirectional representations would yield a strong negative correlation: a high score on is-true implies a low score in is-false.\n",
      "However, the correlation does not approach $-1$ , indicating partial rather than inverse coupling.\n",
      "Together, the two panels show that is-true and is-false directions share some structure but are not strict opposites, spanning a multidimensional subspace rather than a single axis.  \n",
      "In Fig.[3](https://arxiv.org/html/2506.23921v4#S5.F3 \"Figure 3 ‣ 5.1 Veracity Directions ‣ 5 Results ‣ Trilemma of Truth in Large Language Models\").A, we see how different these directions are by computing their cosine similarity.\n",
      "If the two were perfectly opposite, we would expect a cosine similarity of approximately $-1$ .\n",
      "However, this is not the case.\n",
      "The better-performing and more generalizable sAwMIL probe yields directions that are less opposed, suggesting that LLMs encode true and false as related rather than strictly polar concepts.\n",
      "------------------------------\n",
      "Chunk ID: 69092\n",
      "Paper title: Why is prompting hard? Understanding prompts on binary sequence predictors\n",
      "Chunk text: Why is prompting hard? Understanding prompts on binary sequence predictors > 5 Switching DGs and bandit task > 5.1 Switching DGs: The DG below switches periodically between two coins with fixed biases.  \n",
      "###### Definition 5.1 (Switching Process).  \n",
      "$\\textrm{SwitchProc}(\\varepsilon,\\lambda)$ for $\\varepsilon\\in[0,1]$ and $\\lambda\\in\\mathbb{N}_{+}$ generates sequences by  \n",
      "|  |  |  |  |\n",
      "| --- | --- | --- | --- |\n",
      "|  | $\\displaystyle x_{t}$ | $\\displaystyle\\sim\\operatorname{\\mathrm{Bernoulli}}(y_{t})~{}~{}\\forall t\\in\\{1%\n",
      ",\\ldots,T\\},\\text{~{}~{}where}$ |  |\n",
      "|  |  |  |  |\n",
      "| --- | --- | --- | --- |\n",
      "|  | $\\displaystyle y_{1:T}$ | $\\displaystyle=[\\underbrace{\\varepsilon,\\ldots,\\varepsilon}_{\\lambda~{}%\n",
      "\\varepsilon\\text{'s}},\\underbrace{1-\\varepsilon,\\ldots,1-\\varepsilon}_{\\lambda%\n",
      "~{}(1-\\varepsilon)\\text{'s}},\\underbrace{\\varepsilon,\\ldots,\\varepsilon}_{%\n",
      "\\lambda~{}\\varepsilon\\text{'s}},\\ldots]$ |  |  \n",
      "Here, the latent factor $\\tau:=(\\varepsilon,\\lambda)$ . The pretraining DG $p$ is:  \n",
      "###### Definition 5.2 (Random Switching Process).  \n",
      "This DG generates sequences by\n",
      "first sampling\n",
      "$\\varepsilon\\sim\\textrm{Uniform}([0,1])$ and\n",
      "$\\lambda\\sim\\text{Uniform}(\\{3,4,5\\})$ ,\n",
      "then\n",
      "$x_{1:T}\\sim\\text{SwitchProc}(\\varepsilon,\\lambda)$ .  \n",
      "We take $\\textrm{SwitchProc}(\\varepsilon,\\lambda)$ with fixed values of $\\varepsilon$\n",
      "------------------------------\n",
      "Chunk ID: 156801\n",
      "Paper title: Are Formal and Functional Linguistic Mechanisms Dissociated in Language Models?\n",
      "Chunk text: Are Formal and Functional Linguistic Mechanisms Dissociated in Language Models? > 2 Background > 2.1 The Language Network in the Human Brain: That is, the language network responds differentially to language as opposed to non-language stimuli, but it responds equally to syntax as it does to (lexical) semantics; the two do not activate distinct regions of the brain (Fedorenko etal., [2020](https://arxiv.org/html/2503.11302v4#bib.bib27); Shain etal., [2024](https://arxiv.org/html/2503.11302v4#bib.bib100)). Moreover, the language network activates on both linguistic input and output (Menenti etal., [2011](https://arxiv.org/html/2503.11302v4#bib.bib74)). It activates whether the language is heard or read, and is similar across languages (Regev etal., [2013](https://arxiv.org/html/2503.11302v4#bib.bib97); Malik-Moraleda etal., [2022](https://arxiv.org/html/2503.11302v4#bib.bib67)). However, it does not overlap with perceptual or motor regions, and also excludes regions for higher-level non-linguistic competence, such as cognitive control and theory of mind. (Li, Hiersche, and Saygin, [2024](https://arxiv.org/html/2503.11302v4#bib.bib59); Pritchett etal., [2018](https://arxiv.org/html/2503.11302v4#bib.bib92); Quillen, Yen, and Wilson, [2021](https://arxiv.org/html/2503.11302v4#bib.bib94)).\n",
      "------------------------------\n",
      "Chunk ID: 504243\n",
      "Paper title: Planning for Success: Exploring LLM Long-term Planning Capabilities in Table Understanding\n",
      "Chunk text: Planning for Success: Exploring LLM Long-term Planning Capabilities in Table Understanding > Appendix A Prompt: | Comparision | Calculation | Assessment |\n",
      "| You are a Comparison expert. You must use the tools provided to complete the assigned task. We allow you to independently determine how to resolve the assigned goal, such as utilizing the Chain-of-Thought or question decomposition approach, as long as the goal is solved. You can use one tool multiple times and use many tools at one time in any order. You might know the answer without running any code, but you should still run the code to get the answer. Your tools include: {list of predefined functions}. Your task: {shot-term goal}. | You are a Calculation expert. You must use the tools provided to complete the assigned task. We allow you to independently determine how to resolve the assigned goal, such as utilizing the Chain-of-Thought or question decomposition approach, as long as the goal is solved. You can use one tool multiple times and use many tools at one time in any order. You might know the answer without running any code, but you should still run the code to get the answer. Your tools include: {list of predefined functions}. Your task: {shot-term goal} . | You are an Assessment expert. Your goal is to answer the question if sufficient relevant information is available or revise the plan if the results from the Execution experts fail to meet requirements or if the initial plan appears infeasible. Your original plan was this: {plan}. You have currently done the follow steps with the following results at template (step, result): {past\\_steps} |  \n",
      "Table 5: Custom-designed prompts for each component in the PLANTA.\n",
      "------------------------------\n",
      "Chunk ID: 68181\n",
      "Paper title: Agentic Verification for Ambiguous Query Disambiguation\n",
      "Chunk text: Agentic Verification for Ambiguous Query Disambiguation > 4 Method > 4.1 Verified Diversification: This minimizes the input sequence length for each call, optimizing both latency and computational overhead while reducing hallucination in less capable models.  \n",
      "Algorithm 1  Verified Diversification for ambiguous queries  \n",
      "1:Question $q$ ,\n",
      "LLM $\\texttt{LLM}(\\cdot)$  \n",
      "2:Pairs of clarification question and answer $\\hat{\\mathcal{Q}}=\\{(\\hat{q},\\hat{y})\\}$  \n",
      "3: $q^{\\prime}$ $\\leftarrow$ Relax $q$ for high-recall universe  \n",
      "4: $U$ $\\leftarrow$ Top- $k$ retrieved passages from the retriever, using $q^{\\prime}$ as query  \n",
      "5: $\\mathcal{Q}\\leftarrow\\{\\}$  \n",
      "6:for $i=1$ to $k$ do  \n",
      "7: $(\\hat{q}_{i},\\hat{y}_{i})$ $\\leftarrow$ $\\texttt{LLM}(q,p_{i};I_{\\textrm{E}})$  $\\triangleright$ Extracting interpretation from passage $p_{i}$ with execution feedback  \n",
      "8:if $\\hat{q}_{i}$ is not Nonethen  \n",
      "9: $\\mathcal{Q}\\leftarrow\\mathcal{Q}\\cup\\left\\{(\\hat{q}_{i},\\hat{y}_{i})\\right\\}$  \n",
      "10: $\\mathcal{C}$ $\\leftarrow$ Cluster into partitions $\\mathcal{C}_{i}$ ’s of $\\mathcal{Q}$ based on embeddings $f(\\hat{q}_{i};\\hat{y}_{i})$  \n",
      "11: $\\hat{\\mathcal{Q}}\\leftarrow\\{\\}$  \n",
      "12:for $j=1$ to $k$ do  \n",
      "13: $(\\check{q}_{j},\\check{y}_{j})$ $\\leftarrow$ $\\operatornamewithlimits{argmax\\text{ }}_{({q}^{*},y^{*})\\in\\mathcal{C}_{j}}%\n",
      "\\sum_{(\\hat{q},\\hat{y})\\in\\mathcal{C}_{j}}\\mathrm{sim}(f(\\hat{q};\\hat{y}),f(q^%\n",
      "------------------------------\n",
      "Chunk ID: 308925\n",
      "Paper title: GraphGen: Enhancing Supervised Fine-Tuning for LLMs with Knowledge-Driven Synthetic Data Generation\n",
      "Chunk text: GraphGen: Enhancing Supervised Fine-Tuning for LLMs with Knowledge-Driven Synthetic Data Generation > 2 Related Work > 2.3 Combining LLMs and Knowledge Graphs: To enhance factual consistency, hybrid approaches integrating LLMs with KGs have been explored (Guo etal., [2024a](https://arxiv.org/html/2505.20416v1#bib.bib8); Zhao etal., [2024a](https://arxiv.org/html/2505.20416v1#bib.bib40); Yang etal., [2024](https://arxiv.org/html/2505.20416v1#bib.bib35)). These methods leverage KGs to guide text generation, improving reliability while maintaining fluency. However, most focus on general text generation or question answering rather than synthetic data generation for SFT.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = client.retrieve(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    ids=[randint(0, 767801) for _ in range(N)],\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"Given {N} chunks\\n\")\n",
    "for point in results:\n",
    "    print(f\"Chunk ID: {point.id}\")\n",
    "    print(f\"Paper title: {point.payload['Header_1']}\")\n",
    "    print(f\"Chunk text: {point.payload['text']}\")\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a665b-5b9f-4ad6-b678-2128877b8e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81cc54-1a66-4239-9c82-6fb5a1433511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
