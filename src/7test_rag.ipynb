{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43bd2138-08bd-4630-8fb6-66982e9bf4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa933bc-fd4d-486b-ad74-ffa398917f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === КОНФИГ ===\n",
    "EMBED_MODEL_NAME = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "COLLECTION_NAME = \"nlp2025_chunks\"\n",
    "TOP_K = 10\n",
    "LLM_MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bddd91b-81a0-4053-8f69-7a5e178cb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ЗАПРОС ===\n",
    "QUERY = \"Which scientific papers explore graphs within the biomedical domain?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ee2f70-a521-4ec5-b279-5120bec2c77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: CUDA\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on: {device.upper()}\")\n",
    "\n",
    "encoder = SentenceTransformer(EMBED_MODEL_NAME, trust_remote_code=True, device=device)\n",
    "\n",
    "client = QdrantClient(\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db29e0-70e0-4ded-8dc9-8f89f913dd10",
   "metadata": {},
   "source": [
    "## Функция ретривера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e80e80-db4e-4576-8543-7f2e592f1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query_str: str, top_k: int):\n",
    "\n",
    "    query_vector = encoder.encode(query_str, convert_to_numpy=True)\n",
    "\n",
    "    search_results = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=query_vector,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    )\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e585b8f9-9ef8-4ce6-ae7d-0f57f39e10d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Which scientific papers explore graphs within the biomedical domain?\n",
      "------------------------------\n",
      "[1] Score: 0.6980 | ID: 764364\n",
      "Text snippet: Role: You are an expert Biological Graph Annotator....\n",
      "--------------------\n",
      "[2] Score: 0.6849 | ID: 86600\n",
      "Text snippet: Grounding LLM Reasoning with Knowledge Graphs > Appendix A GRBench Statistics: Detailed statistics o...\n",
      "--------------------\n",
      "[3] Score: 0.6573 | ID: 152500\n",
      "Text snippet: What’s In Your Field? Mapping Scientific Research with Knowledge Graphs and LLMs > 3 Demo > 3.2 Quer...\n",
      "--------------------\n",
      "[4] Score: 0.6510 | ID: 698179\n",
      "Text snippet: BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Ge...\n",
      "--------------------\n",
      "[5] Score: 0.6509 | ID: 707191\n",
      "Text snippet: Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing > Appendix...\n",
      "--------------------\n",
      "[6] Score: 0.6468 | ID: 34771\n",
      "Text snippet: Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Lang...\n",
      "--------------------\n",
      "[7] Score: 0.6462 | ID: 707195\n",
      "Text snippet: Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing > Appendix...\n",
      "--------------------\n",
      "[8] Score: 0.6436 | ID: 632856\n",
      "Text snippet: From Knowledge to Treatment: Large Language Model Assisted Biomedical Concept Representation for Dru...\n",
      "--------------------\n",
      "[9] Score: 0.6417 | ID: 767237\n",
      "Text snippet: SciNets: Graph-Constrained Multi-Hop Reasoning for Scientific Literature Synthesis > 10 Ethical Cons...\n",
      "--------------------\n",
      "[10] Score: 0.6394 | ID: 25160\n",
      "Text snippet: Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks > 1 Introduction: | Ad...\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# === ЗАПУСК ТЕСТА ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Query: {QUERY}\\n\" + \"-\"*30)\n",
    "    \n",
    "    results = retrieve(QUERY, top_k=TOP_K)\n",
    "    \n",
    "    if not results.points:\n",
    "        print(\"Ничего не найдено. Проверьте имя коллекции или наличие данных\")\n",
    "    else:\n",
    "        for i, point in enumerate(results.points):\n",
    "            # Извлекаем текст из payload (предполагаем, что поле называется 'text' или 'content')\n",
    "            # Адаптируй ключи payload под свою структуру загрузки\n",
    "            payload = point.payload\n",
    "            score = point.score\n",
    "            \n",
    "            # Пример вывода\n",
    "            print(f\"[{i+1}] Score: {score:.4f} | ID: {point.id}\")\n",
    "            print(f\"Text snippet: {payload.get('text', '')[:100]}...\")\n",
    "            print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62b2c8-3bb1-4507-b7f9-5fe2bd17d693",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f4d11b-1dcc-4d8f-96cd-8a9d6428ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка LLM...\n"
     ]
    }
   ],
   "source": [
    "# === ИНИЦИАЛИЗАЦИЯ МОДЕЛИ ===\n",
    "print(\"Загрузка LLM...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLM_MODEL_NAME,\n",
    "    dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ced29d-3f5a-4ee5-a7bf-ca53e9b6cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rag_answer(query: str, retrieved_chunks) -> str:\n",
    "    \n",
    "    context_text = \"\\n\\n---\\n\\n\".join(retrieved_chunks)\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are a helpful research assistant. \"\n",
    "        \"Answer the user's question mostly based on the provided context below. \"\n",
    "        \"If the answer is not in the context, say so. \"\n",
    "        \"Cite the paper titles if available in the text.\"\n",
    "    )\n",
    "    \n",
    "    user_content = f\"Context:\\n{context_text}\\n\\nQuestion: {query}\"\n",
    "\n",
    "    # 3. Применяем чат-шаблон (ChatML для Qwen)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "    \n",
    "    # Подготовка тензоров\n",
    "    text_input = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text_input], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # 4. Генерация\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.3,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    # 5. Декодирование (убираем промпт из ответа)\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] \n",
    "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22471980-5c11-46db-bca5-3ba50bbbebee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Генерация ответа...\n",
      "\n",
      "=== FINAL ANSWER ===\n",
      "\n",
      "The given context mentions two scientific papers that explore graphs within the biomedical domain:\n",
      "\n",
      "1. \"Graph Neural Networks in Biomedicine\" - This paper surveys the application of Graph Neural Networks (GNNs) in drug discovery.\n",
      "2. \"Knowledge Graphs for Protein Interaction\" - This paper proposes a method using graph databases to map protein interactions.\n",
      "\n",
      "These papers focus specifically on the use of graphs and related concepts such as neural networks and knowledge graphs in biomedicine and bioinformatics contexts respectively.\n"
     ]
    }
   ],
   "source": [
    "# === СИМУЛЯЦИЯ ЗАПУСКА (Интеграция с предыдущим шагом) ===\n",
    "mock_retrieved_chunks = [\n",
    "    \"Title: Graph Neural Networks in Biomedicine. Abstract: This paper surveys the application of GNNs in drug discovery...\",\n",
    "    \"Title: Knowledge Graphs for Protein Interaction. Abstract: We propose a new method using graph databases to map protein interactions...\",\n",
    "    \"Title: Attention Mechanisms in NLP. Abstract: This paper discusses transformers...\" # Нерелевантный пример для теста\n",
    "]\n",
    "\n",
    "QUERY = \"Which scientific papers explore graphs within the biomedical domain?\"\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"Генерация ответа...\")\n",
    "answer = generate_rag_answer(QUERY, mock_retrieved_chunks)\n",
    "\n",
    "print(\"\\n=== FINAL ANSWER ===\\n\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c97dd9-cd13-4026-8f6d-09ef3f5d8c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
