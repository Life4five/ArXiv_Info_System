{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4437d47b-eb46-41a0-9d75-77af8917d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30667942-8812-4b83-be9e-9354314a0714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конфигурация путей\n",
    "# Используем абсолютные пути или относительно корня проекта\n",
    "RAW_DATA_PATH = Path('../data/raw/parquet/')\n",
    "PROCESSED_DATA_PATH = Path('../data/processed/parquet/')\n",
    "\n",
    "# Убедимся, что папка для вывода существует\n",
    "Path(PROCESSED_DATA_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901bc24c-1e50-4d91-95c2-8fc92721d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    from markdownify import markdownify as md\n",
    "    processed_htmls = []\n",
    "    \n",
    "    for html_text in batch['html']:\n",
    "        # 1. Валидация входных данных\n",
    "        if not html_text or \"Conversion to HTML had a Fatal error\" in html_text:\n",
    "            processed_htmls.append(None)\n",
    "            continue\n",
    "            \n",
    "        soup = BeautifulSoup(html_text, 'html.parser')\n",
    "        article = soup.find('article') or soup.find(class_='ltx_page_content')\n",
    "        \n",
    "        if not article:\n",
    "            processed_htmls.append(None)\n",
    "            continue\n",
    "\n",
    "        # 2. Очистка мусора\n",
    "        # Удаляем References\n",
    "        refs_section = soup.find('section', class_='ltx_bibliography')\n",
    "        if refs_section:\n",
    "            refs_section.decompose()\n",
    "            \n",
    "        # Удаляем Acknowledgements\n",
    "        header = soup.find(['h2', 'h3'], string=re.compile(r'^\\s*Acknowledgements?\\s*$', re.IGNORECASE))\n",
    "        if header:\n",
    "            section = header.find_parent('section')\n",
    "            if section:\n",
    "                section.decompose()\n",
    "                \n",
    "        # Удаляем авторов\n",
    "        authors_section = soup.find('div', class_='ltx_authors')\n",
    "        if authors_section:\n",
    "            authors_section.decompose()\n",
    "            \n",
    "        # Удаляем footnotetext\n",
    "        fnt = soup.find('span', class_='ltx_role_footnotetext')\n",
    "        if fnt:\n",
    "            fnt.decompose()\n",
    "            \n",
    "        # Удаляем ошибки\n",
    "        error_section = soup.find('span', class_='ltx_ERROR')\n",
    "        if error_section:\n",
    "            section = error_section.find_parent('div')\n",
    "            if section:\n",
    "                section.decompose()\n",
    "        \n",
    "        # 3. Обработка математики (Latex)\n",
    "        math_registry = {}\n",
    "        for i, math in enumerate(article.find_all(class_='ltx_Math')):\n",
    "            latex = math.get('alttext', '')\n",
    "            if latex:\n",
    "                placeholder = f\"MATHITEM{i}END\" \n",
    "                math_registry[placeholder] = f\"${latex}$\"\n",
    "                math.replace_with(f\" {placeholder} \")\n",
    "\n",
    "        # 4. Конвертация в Markdown\n",
    "        markdown_text = md(str(article), heading_style=\"ATX\")\n",
    "\n",
    "        # 5. Возврат математики на место\n",
    "        for placeholder, original_latex in math_registry.items():\n",
    "            markdown_text = markdown_text.replace(placeholder, original_latex)\n",
    "            \n",
    "        processed_htmls.append(markdown_text)\n",
    "\n",
    "    batch['html'] = processed_htmls\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441104fe-6d8c-48af-b779-94c59e058a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a70df1db59846f2822b8a4269102c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/14594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DatasetDict' object has no attribute 'to_parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      3\u001b[39m ds_processed = ds.map(\n\u001b[32m      4\u001b[39m     process_batch,\n\u001b[32m      5\u001b[39m     batched=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      6\u001b[39m     batch_size=\u001b[32m10\u001b[39m,\n\u001b[32m      7\u001b[39m     num_proc=os.cpu_count()\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m ds_processed = ds_processed.rename_column(\u001b[33m'\u001b[39m\u001b[33mhtml\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmd\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mds_processed\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m(PROCESSED_DATA_PATH / \u001b[33m\"\u001b[39m\u001b[33mprocessed_data.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DatasetDict' object has no attribute 'to_parquet'"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"parquet\", data_files=str(RAW_DATA_PATH / \"*.parquet\"))\n",
    "\n",
    "ds_processed = ds.map(\n",
    "    process_batch,\n",
    "    batched=True,\n",
    "    batch_size=10,\n",
    "    num_proc=os.cpu_count()\n",
    ")\n",
    "\n",
    "ds_processed = ds_processed.rename_column('html', 'md')\n",
    "ds_processed['train'].to_parquet(PROCESSED_DATA_PATH / \"processed_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db438703-2167-406b-98b3-bd1698b4659e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
