# ArXiv Info System

Вопросно-ответная RAG-система (RAG – Retrieval-Augmented Generation) по научным статьям с [arxiv.org](https://arxiv.org/).

**Автор проекта:** [Демидов Константин](https://github.com/ConstDemi)  
**Руководитель проекта:** [Паточенко Евгений](https://github.com/evgpat)


## Структура проекта

```text
info.ipynb               Паспорт проекта (описание целей, методологии, прогресса)
data_parse.ipynb         Парсинг статей arXiv

data/                    рабочее хранилище данных проекта (создастся при запуске data_parse.ipynb)
└── raw/                 "сырые" (необработанные) статьи
    ├── tex/             архивы LaTeX-исходников статей (.tar.gz)
    └── pdf/             PDF-версии статей
```

## Парсинг данных с arXiv

### Описание
Скрипт `data_parse.ipynb` реализует сбор научных статей из arXiv через Python библиотеку `arxiv`. Основная цель — загрузка статей по NLP для последующей обработки в RAG-системе.

### Целевая категория
Парсинг ведется по категории **cs.CL (Computation and Language)**, которая охватывает статьи по:
- Natural Language Processing
- Computational Linguistics  
- Speech processing
- Text retrieval

## Технические детали

**Параметры поиска:**
- Запрос: `cat:cs.CL` (поиск по категории)
- Сортировка: по дате публикации (от новых к старым)
- Лимит: настраивается через переменную `N`

### Важные особенности реализации

1. **Фильтрация по primary category**  
   arXiv API возвращает статьи, где cs.CL указана как основная ИЛИ дополнительная категория. Скрипт фильтрует результаты, оставляя только статьи с `primary_category == 'cs.CL'`.

2. **Соблюдение rate limits**  
   Задержка в 3 секунды между запросами — обязательное требование arXiv для корректной работы с API.

3. **Двойная загрузка**  
   Для каждой статьи скачиваются:
   - **LaTeX исходники** (.tar.gz) — приоритетный формат для извлечения текста
   - **PDF документ** — резервный вариант на случай проблем с LaTeX

Каждая статья сохраняется с идентификатором arXiv (например, `2411.12345v1`).
