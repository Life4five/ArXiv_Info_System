{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f166ec4-7bf2-49e6-a10e-5326fae13da3",
   "metadata": {},
   "source": [
    "# Парсинг статей с помощью библиотеки arxiv\n",
    "Нас интересуют статьи, касающиеся NLP. Это категория cs.CL.\n",
    "\n",
    "Инфа из arXiv Category Taxonomy:\n",
    "> **cs.CL (Computation and Language)**\n",
    ">\n",
    ">  Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1185de5b-b839-4c14-b818-bcdfa4ff9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "import urllib.request\n",
    "\n",
    "import arxiv\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f4df03-59a2-4526-beea-2d0b15d0b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Штука чтобы не было SSL Certificate error\n",
    "ctx = ssl.create_default_context(cafile=certifi.where())\n",
    "\n",
    "https_handler = urllib.request.HTTPSHandler(context=ctx)\n",
    "opener = urllib.request.build_opener(https_handler)\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d74e23-75d2-4546-8ec7-927867eb2a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ПЕРЕМЕННЫЕ И ДИРЕКТОРИИ =====\n",
    "N = 100 # Количество статей в поиске. После фильтрации по категории количество может уменьшиться\n",
    "CAT = 'cs.CL' # Целевая категория, которую хотим парсить.\n",
    "\n",
    "# Куда будем скачивать данные\n",
    "DATA_DIR = Path('data')\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_TEX_DIR = Path('data/raw/tex')\n",
    "RAW_TEX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_PDF_DIR = Path('data/raw/pdf')\n",
    "RAW_PDF_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e5f007-b9bf-47aa-b670-14bc1f61e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = arxiv.Client(\n",
    "    page_size=100,\n",
    "    delay_seconds=3,\n",
    "    num_retries=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd5c4e0-a8b8-4e74-bc6a-95206f18a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ищем N статей с категорией cs.CL, сортирует по самым свежим статьям\n",
    "# Важно: в поиске будут статьи не только primary category, но и cross-list category. Arxiv не умеет искать только по primary category.\n",
    "search = arxiv.Search(\n",
    "    query=f\"cat:{CAT}\",\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "    max_results=N\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a1eda3f-8d76-4e0c-9a5b-e91810c599da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Скачивание статей...: 100%|██████████████████████████████████████████████████████████| 100/100 [00:54<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачано 74 статей с главной категорией cs.CL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Скачиваем только те статьи у которых primary category - cs.CL\n",
    "cnt = 0\n",
    "for p in tqdm(client.results(search), desc='Скачивание статей...', total=N):\n",
    "    if p.primary_category == CAT:\n",
    "        p.download_source(dirpath=str(RAW_TEX_DIR)) # качаем TeX source\n",
    "        p.download_pdf(dirpath=str(RAW_PDF_DIR)) # качаем pdf статьи\n",
    "        cnt += 1\n",
    "print(f'Скачано {cnt} статей с главной категорией {CAT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a02d2a-c8e9-4f75-b616-e48f7bcd9416",
   "metadata": {},
   "source": [
    "После парсинга мы получаем в папке data директорию для каждой статьи, где хранятся LaTeX исходники и PDF документ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae8bba-5a10-4cd8-b9e6-7f3d039bc7d8",
   "metadata": {},
   "source": [
    "Также скорость скачивания довольно медленная. Сейчас не критично, но при масштабировании можно оптимизировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26cba4f-2261-4086-aae7-27061cd30635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
